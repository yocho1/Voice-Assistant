# Voice Assistant

> A production-ready AI voice assistant combining Google Gemini's conversation capabilities with local Whisper speech-to-text and Coqui TTS speech synthesis. Built with Flask and featuring a modern, responsive web UI.

[![Python 3.11+](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Docker](https://img.shields.io/badge/Docker-Available-blue.svg)](Dockerfile)

## âœ¨ Features

### Core Capabilities
- **Gemini-Powered Conversations** â€“ Uses Google's Gemini API with 5-message short-term memory
- **Local Speech-to-Text** â€“ OpenAI Whisper with multi-format audio support (WAV, WebM, MP3, OGG)
- **Natural Speech Synthesis** â€“ Coqui TTS for audio responses with optional voice selection
- **Cross-Platform Audio** â€“ Auto-converts audio formats via ffmpeg for seamless processing

### User Experience
- **Voice Recording** â€“ Browser-native MediaRecorder with waveform visualization
- **Automatic Silence Detection** â€“ Audio stops recording after 1.2s of silence
- **Live Transcripts** â€“ Real-time transcription display with language detection
- **Dark/Light Mode** â€“ Theme preference persists across sessions
- **Copy-to-Clipboard** â€“ Quickly export AI responses
- **Responsive Design** â€“ Mobile-first, works on desktop/tablet/phone

### Developer-Friendly
- **REST API** â€“ Clean, predictable endpoints for all operations
- **Rate Limiting** â€“ IP-based rate limiting (configurable per minute)
- **CORS Enabled** â€“ Cross-origin requests supported
- **Comprehensive Logging** â€“ Detailed error and debug information
- **Docker Support** â€“ Multi-stage build with optimized image size
- **Health Checks** â€“ Built-in service status monitoring

## ğŸš€ Quick Start

### Option 1: Docker (Recommended)

```bash
# Clone and enter directory
git clone https://github.com/yocho1/Voice-Assistant.git
cd Voice-Assistant

# Copy environment template
cp .env.example .env

# Get a free Gemini API key from https://aistudio.google.com/app/apikey
# Edit .env and update GEMINI_API_KEY

# Build and run
docker-compose up --build
```

Visit http://localhost:5000

### Option 2: Local Development

**Requirements:** Python 3.11+, ffmpeg, espeak-ng

```bash
# Create virtual environment
python -m venv .venv
.venv\Scripts\activate  # Windows
# OR
source .venv/bin/activate  # macOS/Linux

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your Gemini API key

# Run
python app.py
```

Visit http://localhost:5000

## ğŸ“‹ API Documentation

### Health & Status
```http
GET /health
```
Returns service status and model availability.

### Chat Endpoint
```http
POST /api/chat
Content-Type: application/json

{
  "message": "What is machine learning?",
  "audio": true
}
```
**Response:**
```json
{
  "reply": "Machine learning is...",
  "audio_url": "/static/audio/tts-abc123.wav",
  "history": [...]
}
```

### Speech-to-Text
```http
POST /api/speech-to-text
Content-Type: multipart/form-data

file: <audio_file>
language: en (optional)
```
**Response:**
```json
{
  "transcript": "hello world",
  "segments": [
    {
      "text": "hello",
      "start": 0.0,
      "end": 0.5
    }
  ],
  "language": "en"
}
```

### Text-to-Speech
```http
POST /api/text-to-speech
Content-Type: application/json

{
  "text": "Hello, world!",
  "voice": "en-US"
}
```
**Response:**
```json
{
  "audio_url": "/static/audio/tts-xyz789.wav"
}
```

### Conversation Management
```http
GET /api/conversation
```
Get current conversation history (trimmed).

```http
POST /api/conversation/reset
```
Clear all conversation history.

## âš™ï¸ Configuration

Create a `.env` file based on `.env.example`:

### Gemini Settings
- `GEMINI_API_KEY` â€“ API key from https://aistudio.google.com/app/apikey
- `GEMINI_MODEL` â€“ Model to use (default: `gemini-1.5-flash`)
- `GEMINI_TEMPERATURE` â€“ Creativity level 0.0â€“2.0 (default: `0.7`)
- `GEMINI_MAX_TOKENS` â€“ Max response length (default: `512`)

### Speech Settings
- `WHISPER_MODEL` â€“ Model size: `tiny`, `base`, `small`, `medium`, `large` (default: `base`)
- `TTS_MODEL` â€“ Coqui model path (default: `tts_models/en/ljspeech/tacotron2-DDC`)
- `TTS_VOICE` â€“ Voice ID for synthesis (default: `en-US`)
- `AUDIO_FORMAT` â€“ Output format: `wav` or `mp3` (default: `wav`)

### Server Settings
- `FLASK_SECRET_KEY` â€“ Session encryption key
- `PORT` â€“ Server port (default: `5000`)
- `REQUESTS_PER_MINUTE` â€“ Rate limit (default: `60`)
- `CONVERSATION_WINDOW` â€“ Messages to retain (default: `5`)
- `MAX_AUDIO_AGE_MINUTES` â€“ Audio cleanup age (default: `60`)
- `MAX_UPLOAD_MB` â€“ Max upload size (default: `25`)

## ğŸ“ Project Structure

```
voice-assistant/
â”œâ”€â”€ app.py                 # Flask backend with API routes
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ Dockerfile             # Container definition
â”œâ”€â”€ docker-compose.yml     # Multi-service orchestration
â”œâ”€â”€ .env.example          # Environment template
â”œâ”€â”€ .gitignore            # Git exclusions
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css     # Dark/light theme with animations
â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â””â”€â”€ voice.js      # Browser audio & API client
â”‚   â””â”€â”€ audio/            # Generated audio files (temp)
â””â”€â”€ templates/
    â””â”€â”€ index.html        # Single-page application
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Browser (MediaRecorder, Web Audio API)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Flask REST API (Rate Limiting, CORS)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”œâ”€ Chat Route â†’ Gemini API                        â”‚
â”‚  â”œâ”€ STT Route â†’ Whisper (ffmpeg conversion)        â”‚
â”‚  â”œâ”€ TTS Route â†’ Coqui (audio synthesis + caching)  â”‚
â”‚  â””â”€ Conversation Management                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚          â”‚          â”‚          â”‚
 â”Œâ”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”
 â”‚Audioâ”‚  â”‚Gemini â”‚  â”‚Whisperâ”‚  â”‚Coqui â”‚
 â”‚Filesâ”‚  â”‚  API  â”‚  â”‚Models â”‚  â”‚ TTS  â”‚
 â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ³ Docker Deployment

### Build
```bash
docker-compose build
```

### Run
```bash
docker-compose up
```

### Logs
```bash
docker-compose logs -f voice-assistant
```

### Stop
```bash
docker-compose down
```

The Docker image includes:
- Python 3.11 slim base
- ffmpeg for audio conversion
- espeak-ng for text-to-speech
- All Python dependencies
- Optimized multi-stage build (~2GB final image)

## ğŸ”§ Troubleshooting

### Models take too long to load
- First run downloads Whisper (~300MB) and Coqui models (~1GB)
- Gunicorn timeout increased to 5 minutes for model initialization
- Subsequent runs use cached models (much faster)

### "Gemini not configured" error
- Verify `GEMINI_API_KEY` is set in `.env`
- Check API key validity at https://aistudio.google.com/app/apikey
- Ensure key has quota available

### "ffmpeg is required" error
- **Ubuntu/Debian:** `sudo apt-get install ffmpeg espeak-ng`
- **macOS:** `brew install ffmpeg espeak-ng`
- **Windows:** Download from https://ffmpeg.org/download.html or use WSL2 + apt

### Audio transcription fails
- Ensure file is valid audio (WAV, MP3, WebM, OGG)
- Check file size < 25MB (configurable via `MAX_UPLOAD_MB`)
- Try different language or audio quality

### Rate limiting too strict
- Adjust `REQUESTS_PER_MINUTE` in `.env`
- Note: Gunicorn uses in-memory limiter (not recommended for production clusters)

## ğŸ” Security Considerations

- **API Keys:** Never commit `.env` files; use `.env.example` as template
- **CORS:** Currently allows all origins; restrict in production
- **Rate Limiting:** IP-based and per-route; use Redis for multi-server deployments
- **File Uploads:** Validate MIME types and enforce size limits
- **Audio Cleanup:** Old files auto-pruned; adjust retention via `MAX_AUDIO_AGE_MINUTES`

## ğŸ“Š Performance Notes

- **STT Latency:** Whisper "base" ~5-15s for 30s audio on CPU; larger models slower
- **TTS Latency:** Coqui synthesis ~1-3s per response; caches recent phrases
- **Memory:** ~2GB for all models in memory; use smaller models for constrained environments
- **Concurrency:** Single-worker Docker setup; add workers/load balancer for production

## ğŸ“ API Examples

### Python
```python
import requests

# Chat
response = requests.post('http://localhost:5000/api/chat', json={
    'message': 'Hello!',
    'audio': True
})
print(response.json()['reply'])

# Voice input
with open('recording.wav', 'rb') as f:
    files = {'file': f}
    response = requests.post('http://localhost:5000/api/speech-to-text', files=files)
    print(response.json()['transcript'])
```

### JavaScript
```javascript
// Chat with audio
const response = await fetch('/api/chat', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ message: 'Hi', audio: true })
});
const data = await response.json();
console.log(data.reply);
```

### cURL
```bash
# Health check
curl http://localhost:5000/health

# Chat
curl -X POST http://localhost:5000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"Hello","audio":true}'
```

## ğŸ“„ License

MIT License â€“ see [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“§ Support

- **Issues:** GitHub Issues for bug reports
- **Discussions:** GitHub Discussions for feature requests
- **Documentation:** See inline code comments

## ğŸ—ºï¸ Roadmap

- [ ] Streaming audio responses
- [ ] Multi-turn conversation context window expansion
- [ ] Additional TTS voices and language support
- [ ] Real-time waveform visualization improvements
- [ ] WebSocket support for lower-latency communication
- [ ] Conversation export (PDF/JSON)
- [ ] User authentication and persistent history
- [ ] Mobile native apps (React Native)
